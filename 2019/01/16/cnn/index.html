<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="utf-8">
  
  <title>cnn | WSC_ZOU_Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="前言： 在做识别 MNIST 中用了 CNN 所以看了CNN。 一.CNN（卷积神经网络） 来历： 视皮层中的许多神经元有一个小的局部感受野，这意味着它们只对位于视野中有限的一部分区域的视觉刺激起作用 用途： 可以进行大型图像处理 特点： 该优点在网络的输入是多维图像时表现的更为明显，使图像可以直接作为网络的输入，避免了传统识别算法中复杂的特征提取和数据重建过程，卷积网络是为识别二维形状而特殊设计">
<meta property="og:type" content="article">
<meta property="og:title" content="cnn">
<meta property="og:url" content="http://WSCZou.com/2019/01/16/cnn/index.html">
<meta property="og:site_name" content="WSC_ZOU_Blog">
<meta property="og:description" content="前言： 在做识别 MNIST 中用了 CNN 所以看了CNN。 一.CNN（卷积神经网络） 来历： 视皮层中的许多神经元有一个小的局部感受野，这意味着它们只对位于视野中有限的一部分区域的视觉刺激起作用 用途： 可以进行大型图像处理 特点： 该优点在网络的输入是多维图像时表现的更为明显，使图像可以直接作为网络的输入，避免了传统识别算法中复杂的特征提取和数据重建过程，卷积网络是为识别二维形状而特殊设计">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://github.com/apachecn/hands-on-ml-zh/blob/dev/images/chapter_13/13-1.png?raw=true">
<meta property="og:image" content="https://github.com/apachecn/hands-on-ml-zh/raw/dev/images/chapter_13/13-2.png">
<meta property="og:image" content="https://github.com/apachecn/hands-on-ml-zh/raw/dev/images/chapter_13/13-3.png">
<meta property="og:image" content="https://img-blog.csdn.net/20160707204048899">
<meta property="og:image" content="https://github.com/apachecn/hands-on-ml-zh/raw/dev/images/chapter_13/13-5.png">
<meta property="og:image" content="https://github.com/apachecn/hands-on-ml-zh/raw/dev/images/chapter_13/13-6.png">
<meta property="og:image" content="https://github.com/apachecn/hands-on-ml-zh/raw/dev/images/chapter_13/13-8.png">
<meta property="og:image" content="https://github.com/apachecn/hands-on-ml-zh/raw/dev/images/chapter_13/t-13-1.png">
<meta property="og:image" content="https://github.com/apachecn/hands-on-ml-zh/raw/dev/images/chapter_13/t-13-2.png">
<meta property="og:updated_time" content="2019-01-22T06:30:25.220Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="cnn">
<meta name="twitter:description" content="前言： 在做识别 MNIST 中用了 CNN 所以看了CNN。 一.CNN（卷积神经网络） 来历： 视皮层中的许多神经元有一个小的局部感受野，这意味着它们只对位于视野中有限的一部分区域的视觉刺激起作用 用途： 可以进行大型图像处理 特点： 该优点在网络的输入是多维图像时表现的更为明显，使图像可以直接作为网络的输入，避免了传统识别算法中复杂的特征提取和数据重建过程，卷积网络是为识别二维形状而特殊设计">
<meta name="twitter:image" content="https://github.com/apachecn/hands-on-ml-zh/blob/dev/images/chapter_13/13-1.png?raw=true">
  
  
    <link rel="icon" href="/favicon.ico">
  
  <link rel="stylesheet" href="/css/typing.css">
  <link rel="stylesheet" href="/css/donate.css">
  
</head>

  
    
      <body>
    
  
      <div id="container" class="container">
        <article id="post-cnn" class="article article-type-post" itemscope itemprop="blogPost">
  <header id="header" class="header">
  <nav class="mobile-nav">
    <h1 class="nickname">WSC_Zou</h1>
    <ul class="mobile-nav-menu">
      <label for="mobile-menu-toggle"><a>&#9776; Menu</a></label>
      <input type="checkbox" id="mobile-menu-toggle"/>
      <ul class="mobile-nav-link">
        
        <a href="/">Home</a>
        
        <a href="/archives">Archives</a>
        
        <a href="/about">About</a>
        
      </ul>
    </ul>
  </nav>
	
		<nav id="main-nav" class="main-nav nav-left">
	
	
	  <a class="main-nav-link" href="/">Home</a>
	
	  <a class="main-nav-link" href="/archives">Archives</a>
	
	  <a class="main-nav-link" href="/about">About</a>
	
  </nav>
</header>

  <hr/>
  <div class="article-inner">
    

    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      cnn
    </h1>
  

      </header>
    
    <div class="article-entry typo" itemprop="articleBody">
      
        <p>前言：</p>
<p>在做识别 MNIST 中用了 CNN 所以看了CNN。</p>
<h3 id="一-cnn-卷积神经网络">一.CNN（卷积神经网络）</h3>
<p>来历：</p>
<p>视皮层中的许多神经元有一个小的局部感受野，这意味着它们只对位于视野中有限的一部分区域的视觉刺激起作用</p>
<p>用途：</p>
<p>可以进行大型图像处理</p>
<p>特点：</p>
<p>该优点在网络的输入是多维图像时表现的更为明显，使图像可以直接作为网络的输入，避免了传统识别算法中复杂的特征提取和数据重建过程，卷积网络是为识别二维形状而特殊设计的一个多层感知器，这种网络结构对平移、比例缩放、倾斜或者共他形式的变形具有高度不变性。</p>
<p><img src="https://github.com/apachecn/hands-on-ml-zh/blob/dev/images/chapter_13/13-1.png?raw=true" alt="13-1.png"></p>
<p>如图，五个神经元的局部感受野由虚线圆圈表示。不同神经元的感受野可能重叠，并且它们一起平铺了整个视野。注意到一些神经元具有较大的感受野，并且它们对较复杂的模式作出反应，这些模式是较低层模式的组合。这些观察结果让我们想到：更高级别的神经元是基于相邻低级神经元的输出（在图 13-1 中，请注意，每个神经元只与来自前一层的少数神经元相连）。这个强大的结构能够检测视野中任何区域的各种复杂图案。</p>
<h3 id="二-卷积层和卷积核">二.卷积层和卷积核</h3>
<p><img src="https://github.com/apachecn/hands-on-ml-zh/raw/dev/images/chapter_13/13-2.png" alt="img"></p>
<p>CNN 最重要的组成部分是卷积层：第一卷积层中的神经元不是连接到输入图像中的每一个像素（就像它们在前面的章节中那样），而是仅仅连接到它们的局部感受野中的像素（参见图 13-2）。 进而，第二卷积层中的每个神经元只与位于第一层中的小矩形内的神经元连接。 <strong>这种架构允许网络专注于第一隐藏层中的低级特征，然后将其组装成下一隐藏层中的高级特征</strong>，等等。 这种层次结构在现实世界的图像中是很常见的，这也是 CNN 在图像识别方面效果很好的原因之一。</p>
<p>作用：</p>
<p>实现了图片特征提取方法</p>
<p>卷积到底干了什么？</p>
<p>对图像（不同的数据窗口数据）和滤波矩阵（一组固定的权重：因为每个神经元的多个权重固定，所以又可以看做一个恒定的滤波器filter）做<strong>内积</strong>（逐个元素相乘再求和）的操作就是所谓的『卷积』操作</p>
<p><code>fh</code>和<code>fw</code>是局部感受野的高度和宽度（见图 13-3）。 为了使图层具有与前一图层相同的高度和宽度，通常在输入周围添加零，如图所示。 这被称为零填充：通俗地讲就是为了总长能被步长整除。</p>
<p><img src="https://github.com/apachecn/hands-on-ml-zh/raw/dev/images/chapter_13/13-3.png" alt="img"></p>
<p>CNN卷积的计算方式：</p>
<p><img src="https://img-blog.csdn.net/20160707204048899" alt="img"></p>
<p>蓝色的矩阵和红色的矩阵相乘 再加上偏差值就是绿色的值，一一对应。</p>
<p><code>Filter w0</code>和 <code>Filter w2</code> 即为卷积核</p>
<p>可以看到上图中 <code>Filter w0</code>和<code>Filter w2</code>的权重是固定的，这个权重不变即所谓的<code>CNN</code>中的参数（权重） <strong>共享机制</strong></p>
<p>这个机制简化了输入层的值，可以减少隐含层的参数数据量。</p>
<h3 id="三-叠加的多个特征映射">三.叠加的多个特征映射</h3>
<p>什么是特征映射：</p>
<p><img src="https://github.com/apachecn/hands-on-ml-zh/raw/dev/images/chapter_13/13-5.png" alt="img"></p>
<p>特征映射就是 比如上图中一个过滤器表示为中间有一条垂直的白线的黑色正方形(除了中间一列外，这是一个充满 0 的<code>7×7</code>矩阵，除了中央垂直线是 1).则神经元都检测在图像的不同位置处的同一个特征（即匹配与垂直的白线）。将从输入层到隐藏层的这种映射称为特征映射。</p>
<p>下面我们将说到<code>channels</code> 这个概念</p>
<p><img src="https://github.com/apachecn/hands-on-ml-zh/raw/dev/images/chapter_13/13-6.png" alt="img"></p>
<p>我们现在只谈输入图片样本的 <code>channels</code> ：就是指图片的颜色</p>
<p>单色图片的input，是2D， Width x Height<br>
彩色图片的input，是3D， Width x Height x Channels</p>
<p>上图中<code>input layer</code> <code>channels</code>就是3</p>
<p>再说说卷积核：</p>
<p>卷积核的个数大于<code>channels</code> 个数时 图像通常也会越来越深（即更多的特征映射）。但小于输入<code>channels</code> 个数时就变小了 (如 CNN卷积的计算方式 那个动态图)</p>
<h3 id="四-池化层">四. 池化层</h3>
<p>一旦你理解了卷积层是如何工作的，池化层很容易掌握。 他们的目标是对输入图像进行二次抽样（即收缩）以<strong>减少计算负担，内存使用量和参数数量（从而限制过度拟合的风险）</strong>。 减少输入图像的大小也使得神经网络容忍一点点的图像变换（位置不变）。</p>
<p>就像在卷积图层中一样，池化层中的每个神经元都连接到前一层中有限数量的神经元的输出，位于一个小的矩形感受野内。 您必须像以前一样定义其大小，跨度和填充类型。 但是，汇集的神经元没有权重; 它所做的只是使用聚合函数（如最大值或平均值）来聚合输入。 图 13-8 显示了最大池层，这是最常见的池化类型。 在这个例子中，我们使用一个2×2的核，步幅为 2，没有填充。 请注意，只有每个核中的最大输入值才会进入下一层。 其他输入被丢弃。</p>
<p><img src="https://github.com/apachecn/hands-on-ml-zh/raw/dev/images/chapter_13/13-8.png" alt="img"></p>
<p>这显然是一个非常具有破坏性的层：即使只有一个<code>2×2</code>的核和 2 的步幅，输出在两个方向上都会减小两倍（所以它的面积将减少四倍），一下减少了 75% 的输入值</p>
<p>池化层通常独立于每个输入通道工作，因此输出深度与输入深度相同。 接下来可以看到，在这种情况下，图像的空间维度（高度和宽度）保持不变，但是通道数目可以减少。</p>
<h3 id="五cnn架构">五<code>CNN</code>架构</h3>
<p><strong>1.LeNet-5</strong></p>
<p><img src="https://github.com/apachecn/hands-on-ml-zh/raw/dev/images/chapter_13/t-13-1.png" alt="img"></p>
<ul>
<li>
<p><code>Avg Pooing</code>(平均池化层)比平常稍微复杂一些：每个神经元计算输入的平均值，然后将结果乘以一个可学习的系数（每个特征映射一个），并添加一个可学习的偏差项（每个特征映射一个），然后最后应用激活函数。</p>
</li>
<li>
<p>输出层有点特殊：每个神经元不是计算输入和权向量的点积，而是输出其输入向量和其权向量之间的欧几里德距离的平方。每个输出测量图像属于特定数字类别的多少。 交叉熵损失函数现在是首选，因为它更多地惩罚不好的预测，产生更大的梯度，从而更快地收敛。</p>
</li>
</ul>
<p><strong>2.AlexNet</strong></p>
<p><img src="https://github.com/apachecn/hands-on-ml-zh/raw/dev/images/chapter_13/t-13-2.png" alt="img"></p>

      
      
    </div>
    <footer class="article-footer">
      <ul class="article-meta">
        <li>
          <span class="label">Published Date:</span>
          <a href="/2019/01/16/cnn/" class="article-date">
  <time datetime="2019-01-16T03:18:29.000Z" itemprop="datePublished">2019-01-16</time>
</a>

        </li>
        
        
        <hr/>
      </ul>
    </footer>
  </div>
  
    
<nav id="article-nav" class="article-nav">
  
    <span id="article-nav-newer" class="article-nav-link-wrap newer"></span>
  
  
    <a href="/2019/01/14/vultr搭建ssr/" id="article-nav-older" class="article-nav-link-wrap older">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">vultr搭建ssr</div>
    </a>
  
</nav>


  
</article>










      </div>
      
    <footer id="footer" class="post-footer footer">
      
      <hr/>
      <div id="footerContent" class="footer-content">
        <p>writing…</p>


      </div>
    </footer>

      







<script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>


  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css">
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>


<script src="/js/typing.js"></script>
<!--[if lt IE 9]><script src="https://cdn.jsdelivr.net/npm/html5shiv@3/dist/html5shiv.min.js"></script><![endif]-->







    </div>
  </body>
</html>
